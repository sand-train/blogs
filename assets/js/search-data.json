{
  
    
        "post0": {
            "title": "Python classes",
            "content": "class Example: # default constructor def __init__(self, n, m): &#39;&#39;&#39;Example of a Python class with three parameters, including self. Arguments map to n and m.&#39;&#39;&#39; print(&quot;Address of self = &quot;,id(self)) self.name = n self.mood = m def say(self,x): &#39;&#39;&#39;Method of the class Example with two parameters, including self. Note that this method only takes one argument mapping to x.&#39;&#39;&#39; self.instance_attribute = x return f&#39;Hello {self.name}, {x}! This is {self.mood}!&#39; . Instance of a class . We invoke any class&#39;s instance-making function by using the name of the class as a function. In our case, the name of our class is Example, so the name of the instance-creation function is Example(). . ex is an instance of the class Example: . ex = Example(&#39;Sandra&#39;, &#39;Exciting&#39;) print(ex.say(&quot;let&#39;s learn about classes&quot;)) . Hello Sandra, let&#39;s learn about classes! This is Exciting! . Attributes of a class . Let&#39;s list the attributes of the class by using dir(my_instance). Python uses the word attribute to indicate both the methods of an object and the names of any values stored in an object. An attribute is a name associated with another object. Note that a class is also an object. . dir(ex) . [&#39;__class__&#39;, &#39;__delattr__&#39;, &#39;__dict__&#39;, &#39;__dir__&#39;, &#39;__doc__&#39;, &#39;__eq__&#39;, &#39;__format__&#39;, &#39;__ge__&#39;, &#39;__getattribute__&#39;, &#39;__gt__&#39;, &#39;__hash__&#39;, &#39;__init__&#39;, &#39;__init_subclass__&#39;, &#39;__le__&#39;, &#39;__lt__&#39;, &#39;__module__&#39;, &#39;__ne__&#39;, &#39;__new__&#39;, &#39;__reduce__&#39;, &#39;__reduce_ex__&#39;, &#39;__repr__&#39;, &#39;__setattr__&#39;, &#39;__sizeof__&#39;, &#39;__str__&#39;, &#39;__subclasshook__&#39;, &#39;__weakref__&#39;, &#39;instance_attribute&#39;, &#39;mood&#39;, &#39;name&#39;, &#39;say&#39;] . A special argument: self . It&#39;s odd that in our previous example of a class, we only passed one argument (a string); however, two parameters showed up in the definition of the method self and x. . self is associated with the instance being made, that is the object that called the method. Python will automatically map the first parameter in a method definition to the object that called the method. . In our previous example ex maps to self, while &quot;let&#39;s learn about classes&quot; maps to x. . The self must always be placed as the first parameter in any method definition. . We can also see that self has a new attribute called instance_attribute. Let us print this ro see that say assigns x to the instance_attribute. . print(&quot;Instance has new attribute with value: &quot;,ex.instance_attribute) . NameError Traceback (most recent call last) /var/folders/g_/1l894xhd10g6tj9857m75k8r0000gn/T/ipykernel_8614/2259833054.py in &lt;module&gt; -&gt; 1 print(&#34;Instance has new attribute with value: &#34;,ex.instance_attribute) NameError: name &#39;ex&#39; is not defined . Finally, we can see in the code below that self and my_instance is referring to the same object. . my_instance = Example(&#39;Sandra&#39;, &#39;Exciting&#39;) print(&quot;Address of class object = &quot;,id(my_instance)) . Address of self = 140430184214032 Address of class object = 140430184214032 . Classes we can re-use for ML . https://scipython.com/book2/chapter-4-the-core-python-language-ii/examples/a-2d-vector-class/ . Dot Product . import numpy as np . class Vec2D: def __init__(self,x, y): &#39;&#39;&#39;A 2-D vector with Cartesian coordinates.&#39;&#39;&#39; self.x = x self.y = y print(x,y) def dp(self, other): &#39;&#39;&#39;Computes the dot product of two vectors with only 2-D Cartesian coordinates.&#39;&#39;&#39; # return self.x * other.x + self.y * other.y return np.sum((self.x * other.x, self.y * other.y)) . x = Vec2D(2,-3) y = Vec2D(4,5) dot_product = x.dp(y) print(&#39;vector1.dp(vector2) = &#39;, dot_product) . 2 -3 4 5 vector1.dp(vector2) = -7 . class Vectors: def __init__(self,a,b): &#39;&#39;&#39;Takes two vectors of any length.&#39;&#39;&#39; self.a = a self.b = b print(a,b) def dp(self): &#39;&#39;&#39;Checks vectors are of equal length and computes dot product.&#39;&#39;&#39; try: assert (len(a) == len(b)), f&quot;Vectors {a} and {b} are not of equal length.&quot; return sum(x * y for x, y in zip(a,b)) # zip will lead to issues with dot products when vectors are not the same length except AssertionError as msg: print(msg) . a = [1, 2, 3, 4] b = [0.5, 0.1, 0.2, 0.2] v = Vectors(a,b) dot_product = v.dp() print(dot_product) . [1, 2, 3, 4] [0.5, 0.1, 0.2, 0.2] 2.1 .",
            "url": "https://sand-train.github.io/blogs/python/",
            "relUrl": "/python/",
            "date": " • Oct 7, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "Title",
            "content": "import numpy as np from scipy import signal from scipy.fft import fft, ifft, fftfreq import matplotlib.pyplot as plt . Fc = 50 Fs = 800 t = np.arange(0,Fs,1/Fs) # t = np.linspace(0.0, Fs, 1/Fs, endpoint=False) Ns = len(t) T = Ns/Fs df= Fs/Ns x = np.cos(2*np.pi*Fc*t) #+ 0.5*np.randn(L,1) z = np.exp(2*np.pi*1j*Fc*t) x_delayed = np.pad(x, (100,100), mode=&#39;constant&#39;, constant_values=0) Ns x_delayed[:-1] plt.plot(t[0:200],x[0:200]) plt.plot(t[200:300],x[200:300]) plt.show() . Zero-pad . Reference: https://dsp.stackexchange.com/questions/741/why-should-i-zero-pad-a-signal-before-taking-the-fourier-transform . &quot;Zero padding allows one to use a longer FFT, which will produce a longer FFT result vector. . A longer FFT result has more frequency bins that are more closely spaced in frequency. But they will be essentially providing the same result as a high quality Sinc interpolation of a shorter non-zero-padded FFT of the original data. . This might result in a smoother looking spectrum when plotted without further interpolation. . Although this interpolation won&#39;t help with resolving or the resolution of and/or between adjacent or nearby frequencies, it might make it easier to visually resolve the peak of a single isolated frequency that does not have any significant adjacent signals or noise in the spectrum. Statistically, the higher density of FFT result bins will probably make it more likely that the peak magnitude bin is closer to the frequency of a random isolated input frequency sinusoid, and without further interpolation (parabolic, et.al.). . But, essentially, zero padding before a DFT/FFT is a computationally efficient method of interpolating a large number of points. . Zero-padding for cross-correlation, auto-correlation, or convolution filtering is used to not mix convolution results (due to circular convolution). The full result of a linear convolution is longer than either of the two input vectors. If you don&#39;t provide a place to put the end of this longer convolution result, FFT fast convolution will just mix it in with and cruft up your desired result. Zero-padding provides a bunch zeros into which to mix the longer result. And it&#39;s far far easier to un-mix something that has only been mixed/summed with a vector of zeros.&quot; . Nfft = 600 # This is important for the convolution? r_padded = np.pad(x, (0,Nfft), mode=&#39;constant&#39;, constant_values=0) plt.plot(r_padded[:-20]) plt.show() . R = fft(r_padded, Nfft) #replica in the frequency domain Rf = fftfreq(Nfft, 1/Fs)[:Nfft//2] plt.plot(Rf, 2.0/Nfft * np.abs(R[0:Nfft//2])) plt.grid() plt.show() . N = 600 # sample spacing T = 1.0 / 800.0 x = np.linspace(0.0, N*T, N, endpoint=False) y = np.sin(50.0 * 2.0*np.pi*x) + 0.5*np.sin(80.0 * 2.0*np.pi*x) yf = fft(y, 1*N) xf = fftfreq(N, T)[:N//2] plt.plot(xf, 2.0/N * np.abs(yf[0:N//2])) plt.grid() plt.show() .",
            "url": "https://sand-train.github.io/blogs/2022/08/29/sync_correlation.html",
            "relUrl": "/2022/08/29/sync_correlation.html",
            "date": " • Aug 29, 2022"
        }
        
    
  
    
        ,"post2": {
            "title": "Bear Classifier",
            "content": "Let&#39;s load our Dataset . import os os.listdir(&#39;./gdrive&#39;) . [&#39;Othercomputers&#39;, &#39;MyDrive&#39;, &#39;.file-revisions-by-id&#39;, &#39;.shortcut-targets-by-id&#39;, &#39;.Trash-0&#39;] . from fastai.vision.all import * path = Path(r&quot;./gdrive/MyDrive/Colab Notebooks/images/bears&quot;) # from pathlib import Path path . Path(&#39;.&#39;) . Path.BASE_PATH = path type(Path.BASE_PATH) . pathlib.PosixPath . dest = path / &#39;black&#39; / &#39;00000000.jpg&#39; im = Image.open(dest) im.to_thumb(128,128) . bear_types = &#39;grizzly&#39;,&#39;black&#39;,&#39;teddys&#39; . fns = get_image_files(path) # path, and returns a list of all of the images in that path fns[-1] . Path(&#39;teddys/00000101.png&#39;) . def parent_label_multi(file_name): return [parent_label(file_name)] #returns a list of labels based on the name of the folder a file is in . bears = DataBlock( blocks=(ImageBlock, MultiCategoryBlock), get_items=get_image_files, splitter=RandomSplitter(valid_pct=0.2, seed=42), get_y=parent_label_multi, item_tfms=Resize(128)) . Datasets using the data block API . Using the bears data block, we can create a Datasets object from this by passing the source -- in this case, the path to our images. . dsets=bears.datasets(path) len(dsets.train),len(dsets.valid) . (418, 104) . dsets now contain a train and valid dataset. . x,y = dsets.train[0] x,y . (PILImage mode=RGB size=375x500, TensorMultiCategory([1., 0., 0.])) . firstSample_OH=dsets.train[0][1] firstSample_OH . TensorMultiCategory([1., 0., 0.]) . idxs = torch.where(firstSample_OH==1.)[0] dsets.train.vocab[idxs] . (#1) [&#39;black&#39;] . DataLoaders using the data block API . Now that we have a template bears in the form of a DataBlock object, we can use it to create a DataLoaders pointing to the path where the source of our data is. . Recall: . DataLoaders:: An object that contains a training DataLoader and a validation DataLoader . dls = bears.dataloaders(path) dls.train.show_batch(max_n=16, nrows=4, unique=True) . xb,yb = dls.one_batch() xb.shape,yb.shape . (torch.Size([64, 3, 128, 128]), torch.Size([64, 3])) . xb[0] . TensorImage([[[0.9961, 0.9961, 0.9961, ..., 0.9961, 0.9961, 0.9961], [0.9961, 0.9961, 0.9961, ..., 0.9961, 0.9961, 0.9961], [1.0000, 1.0000, 1.0000, ..., 1.0000, 1.0000, 1.0000], ..., [1.0000, 1.0000, 1.0000, ..., 1.0000, 1.0000, 1.0000], [1.0000, 1.0000, 1.0000, ..., 1.0000, 1.0000, 1.0000], [1.0000, 1.0000, 1.0000, ..., 1.0000, 1.0000, 1.0000]], [[0.9961, 0.9961, 0.9961, ..., 0.9961, 0.9961, 0.9961], [0.9961, 0.9961, 0.9961, ..., 0.9961, 0.9961, 0.9961], [1.0000, 1.0000, 1.0000, ..., 1.0000, 1.0000, 1.0000], ..., [1.0000, 1.0000, 1.0000, ..., 1.0000, 1.0000, 1.0000], [1.0000, 1.0000, 1.0000, ..., 1.0000, 1.0000, 1.0000], [1.0000, 1.0000, 1.0000, ..., 1.0000, 1.0000, 1.0000]], [[0.9961, 0.9961, 0.9961, ..., 0.9961, 0.9961, 0.9961], [0.9961, 0.9961, 0.9961, ..., 0.9961, 0.9961, 0.9961], [1.0000, 1.0000, 1.0000, ..., 1.0000, 1.0000, 1.0000], ..., [1.0000, 1.0000, 1.0000, ..., 1.0000, 1.0000, 1.0000], [1.0000, 1.0000, 1.0000, ..., 1.0000, 1.0000, 1.0000], [1.0000, 1.0000, 1.0000, ..., 1.0000, 1.0000, 1.0000]]], device=&#39;cuda:0&#39;) . yb[0] #an example row from the dependent variable . TensorMultiCategory([0., 0., 1.], device=&#39;cuda:0&#39;) . df_y_OH = pd.DataFrame(yb) df_y_OH.columns = bear_types df_y_OH.head() . grizzly black teddys . 0 0.0 | 0.0 | 1.0 | . 1 0.0 | 0.0 | 1.0 | . 2 0.0 | 0.0 | 1.0 | . 3 1.0 | 0.0 | 0.0 | . 4 0.0 | 0.0 | 1.0 | . bears.summary(path) . Setting-up type transforms pipelines Collecting items from gdrive/MyDrive/Colab Notebooks/images/bears Found 522 items 2 datasets of sizes 418,104 Setting up Pipeline: PILBase.create Setting up Pipeline: parent_label_multi -&gt; MultiCategorize -- {&#39;vocab&#39;: None, &#39;sort&#39;: True, &#39;add_na&#39;: False} -&gt; OneHotEncode -- {&#39;c&#39;: None} Building one sample Pipeline: PILBase.create starting from gdrive/MyDrive/Colab Notebooks/images/bears/black/00000015.jpg applying PILBase.create gives PILImage mode=RGB size=375x500 Pipeline: parent_label_multi -&gt; MultiCategorize -- {&#39;vocab&#39;: None, &#39;sort&#39;: True, &#39;add_na&#39;: False} -&gt; OneHotEncode -- {&#39;c&#39;: None} starting from gdrive/MyDrive/Colab Notebooks/images/bears/black/00000015.jpg applying parent_label_multi gives [black] applying MultiCategorize -- {&#39;vocab&#39;: None, &#39;sort&#39;: True, &#39;add_na&#39;: False} gives TensorMultiCategory([0]) applying OneHotEncode -- {&#39;c&#39;: None} gives TensorMultiCategory([1., 0., 0.]) Final sample: (PILImage mode=RGB size=375x500, TensorMultiCategory([1., 0., 0.])) Collecting items from gdrive/MyDrive/Colab Notebooks/images/bears Found 522 items 2 datasets of sizes 418,104 Setting up Pipeline: PILBase.create Setting up Pipeline: parent_label_multi -&gt; MultiCategorize -- {&#39;vocab&#39;: None, &#39;sort&#39;: True, &#39;add_na&#39;: False} -&gt; OneHotEncode -- {&#39;c&#39;: None} Setting up after_item: Pipeline: Resize -- {&#39;size&#39;: (128, 128), &#39;method&#39;: &#39;crop&#39;, &#39;pad_mode&#39;: &#39;reflection&#39;, &#39;resamples&#39;: (2, 0), &#39;p&#39;: 1.0} -&gt; ToTensor Setting up before_batch: Pipeline: Setting up after_batch: Pipeline: IntToFloatTensor -- {&#39;div&#39;: 255.0, &#39;div_mask&#39;: 1} Building one batch Applying item_tfms to the first sample: Pipeline: Resize -- {&#39;size&#39;: (128, 128), &#39;method&#39;: &#39;crop&#39;, &#39;pad_mode&#39;: &#39;reflection&#39;, &#39;resamples&#39;: (2, 0), &#39;p&#39;: 1.0} -&gt; ToTensor starting from (PILImage mode=RGB size=375x500, TensorMultiCategory([1., 0., 0.])) applying Resize -- {&#39;size&#39;: (128, 128), &#39;method&#39;: &#39;crop&#39;, &#39;pad_mode&#39;: &#39;reflection&#39;, &#39;resamples&#39;: (2, 0), &#39;p&#39;: 1.0} gives (PILImage mode=RGB size=128x128, TensorMultiCategory([1., 0., 0.])) applying ToTensor gives (TensorImage of size 3x128x128, TensorMultiCategory([1., 0., 0.])) Adding the next 3 samples No before_batch transform to apply Collating items in a batch Applying batch_tfms to the batch built Pipeline: IntToFloatTensor -- {&#39;div&#39;: 255.0, &#39;div_mask&#39;: 1} starting from (TensorImage of size 4x3x128x128, TensorMultiCategory of size 4x3) applying IntToFloatTensor -- {&#39;div&#39;: 255.0, &#39;div_mask&#39;: 1} gives (TensorImage of size 4x3x128x128, TensorMultiCategory of size 4x3) . Let&#39;s train our model . We will find a learning rate using learn.lr_find() . learn = cnn_learner(dls, resnet50, metrics=partial(accuracy_multi), ) # cbs=[WandbCallback(), SaveModelCallback()]) learn.lr_find() . Downloading: &#34;https://download.pytorch.org/models/resnet50-0676ba61.pth&#34; to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at /pytorch/c10/core/TensorImpl.h:1156.) return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode) . SuggestedLRs(valley=0.0003981071640737355) . We will now train our model . learn = cnn_learner(dls, resnet50, metrics=partial(accuracy_multi), #cbs=[WandbCallback(), SaveModelCallback()] ) learn.fine_tune(5, base_lr=0.0003981071640737355, freeze_epochs=4) . epoch train_loss valid_loss accuracy_multi time . 0 | 0.989574 | 0.675743 | 0.628205 | 00:19 | . 1 | 0.810696 | 0.264667 | 0.887821 | 00:05 | . 2 | 0.627263 | 0.161804 | 0.948718 | 00:05 | . 3 | 0.490887 | 0.135624 | 0.958333 | 00:05 | . epoch train_loss valid_loss accuracy_multi time . 0 | 0.164186 | 0.131268 | 0.951923 | 00:06 | . 1 | 0.137333 | 0.127039 | 0.955128 | 00:06 | . 2 | 0.117020 | 0.116154 | 0.961538 | 00:06 | . 3 | 0.102201 | 0.112964 | 0.964744 | 00:06 | . 4 | 0.097269 | 0.109486 | 0.967949 | 00:06 | . Let&#39;s get predictions . preds, targs = learn.get_preds() xs = torch.linspace(0.05, 0.95, 10000) accs = [accuracy_multi(preds, targs, thresh=i, sigmoid=False) for i in xs] plt.plot(xs, accs) . [&lt;matplotlib.lines.Line2D at 0x7fda9365f310&gt;] . interp = ClassificationInterpretation.from_learner(learn) interp.plot_confusion_matrix() . Let&#39;s use our trained model and classify some images . uploader = widgets.FileUpload() uploader . img = PILImage.create(uploader.data[0]) img.to_thumb(512) . learn.predict(img) . ((#0) [], tensor([False, False, False]), tensor([0.1184, 0.4531, 0.0730])) . img = PILImage.create(uploader.data[0]) img.to_thumb(512) . learn.predict(img) . ((#1) [&#39;grizzly&#39;], tensor([False, True, False]), tensor([0.0252, 0.9968, 0.0782])) . We can see our classifier has some limitations when it is presented with an image of a panda; it thinks it is a Black bear! . TODO: Need to assign different labels img = PILImage.create(uploader.data[0]) img.to_thumb(512) . learn.predict(img) . ((#1) [&#39;black&#39;], tensor([ True, False, False]), tensor([0.9285, 0.2594, 0.2288])) .",
            "url": "https://sand-train.github.io/blogs/fastcore/",
            "relUrl": "/fastcore/",
            "date": " • Aug 29, 2021"
        }
        
    
  
    
        ,"post3": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://sand-train.github.io/blogs/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Us",
          "content": "Exploring Artificial Intelligence and applications with PyTorch and fast.ai. . Planning to blog about: . Deep Learning | Mathematical breakdown of deep learning | Useful Python packages for practical applications | More to come … | . Topics . Speech and Digital Signal Processing | Natural Language Processing | Computational Biology | .",
          "url": "https://sand-train.github.io/blogs/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://sand-train.github.io/blogs/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}